# Презентация / Демо (скелет)

1. Демонстрация
   - Живой вызов Gradio/Swagger на 2–3 диаграммах из датасета.
   - Показ JSON-ответа и визуального шага-ролей.
2. Гипотезы и обоснование ML-архитектуры
   - Qwen2.5-VL-7B-Instruct: сильный OCR + понимание диаграмм.
   - 4-bit BnB quant: укладываемся <8GB VRAM, скорость 5–15 c.
   - Промпт с жёсткой JSON-схемой → минимальный постпроцессинг.
3. Стек
   - FastAPI + Pydantic + Uvicorn.
   - Transformers + bitsandbytes + PyTorch.
   - Docker + docker-compose, Gradio для демо.
4. Метрики
   - Latency p50/p95 на GPU (целевое: ≤15 c на картинку).
   - VRAM footprint (~5–6 GB при int4).
   - Точность: доля правильно извлечённых шагов/ролей на тестовом наборе (ручной эталон).
5. Почему наше решение выигрывает
   - Лучший компромисс точность/ресурсы: 7B VLM в 4-bit.
   - Простая поставка: одна команда docker-compose.
   - Расширяемость: тот же пайплайн делает Text→Diagram через Mermaid.
6. Дальнейшее развитие
   - Авто-валидатор BPMN (синтаксис, циклы, шлюзы).
   - Active learning: доразметка сложных диаграмм, дообучение LoRA.
   - Кеш подсказок + batch inference для ускорения.
   - Экспорт в BPMN XML / PlantUML / Mermaid.
