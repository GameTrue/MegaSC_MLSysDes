# ML System Design — Чек-поинт 1

Трек Мегашколы ИТМО x Nexign  
Архитектура | Стек | План реализации  
Дата: **2 февраля 2026**

## Раздел 1. Описание архитектуры сервиса

### Задача

Разработать сервис, который распознаёт изображение с диаграммой (BPMN, блок-схемы) и описывает алгоритм, изображённый на диаграмме. Сервис должен работать на GPU с менее 8 GB VRAM, упаковываться в Docker и предоставлять REST API. Опционально: обратная задача (текст → диаграмма).

### Основные компоненты системы

| Компонент | Описание | Технология |
|---|---|---|
| UI (опц.) | Веб-интерфейс для загрузки изображений | Gradio |
| API Gateway | REST эндпоинты, валидация, Swagger | FastAPI |
| Препроцессинг | Ресайз, нормализация изображения | Pillow |
| VLM Inference | Распознавание диаграммы + генерация описания | Qwen2.5-VL-7B (4-bit) |
| Постпроцессинг | Парсинг выхода в JSON | Pydantic |
| Обратная задача (*) | Текст → BPMN/UML диаграмма | VLM + Mermaid |

### Поток данных

Схема обработки запроса:

```text
Пользователь (UI / curl / Swagger)
     |
     v  POST /api/analyze (image file)
+-------------------------+
|     FastAPI Gateway     |
|  валидация, лимиты      |
+-------------------------+
     |
     v
+-------------------------+
|     Препроцессинг       |
|  resize / normalize     |
+-------------------------+
     |
     v
+-------------------------+
|     VLM Inference       |
|  Qwen2.5-VL-7B (4-bit)  |
|  image + prompt -> text |
+-------------------------+
     |
     v
+-------------------------+
|     Постпроцессинг      |
|  text -> JSON           |
+-------------------------+
     |
     v  JSON Response
Пользователь
```

### Детально: вход / обработка / выход

**Вход:**
- Изображение диаграммы (PNG, JPEG, WebP) через `POST /api/analyze`.
- Поддержка BPMN-диаграмм и простых блок-схем.

**Обработка:**
- Препроцессинг: валидация формата, ресайз до оптимального разрешения.
- VLM: мультимодальная модель принимает изображение + промпт, генерирует текстовое описание.
- Постпроцессинг: парсинг выхода в JSON (шаги, названия, роли для BPMN).

**Выход:**
- JSON: `diagram_type`, `steps [{step, action, role}]`, `description`.
- Для простых схем: номер шага + название действия.
- Для BPMN: + роли, пулы (lanes), условия.

### Где используется ML

| Этап | Модель | Что делает |
|---|---|---|
| Основной inference | Qwen2.5-VL-7B-Instruct (AWQ 4-bit) | Изображение + промпт → структурированное описание |
| Обратная задача (*) | Та же VLM (text-only) | Текст → Mermaid/PlantUML код |

### Развёртывание

- Основной: Docker + NVIDIA Container Toolkit (GPU < 8GB VRAM).
- CPU-режим: `llama.cpp` + GGUF `Q4_K_M` (медленнее, но без GPU).
- Запуск: `docker-compose up` (одна команда).

## Раздел 2. Технологический стек

### Язык программирования

| Технология | Обоснование |
|---|---|
| Python 3.11+ | Стандарт для ML/AI. Полная поддержка PyTorch, Transformers, FastAPI. Все модели имеют Python SDK. |

### Backend / API

| Технология | Обоснование |
|---|---|
| FastAPI | Асинхронный фреймворк с авто-генерацией Swagger-документации. Pydantic-валидация из коробки. |
| Uvicorn | ASGI-сервер. Лёгкий и быстрый, подходит для продакшн. |

### ML / VLM

| Технология | Обоснование |
|---|---|
| Qwen2.5-VL-7B-Instruct | VLM с отличным OCR и пониманием схем. Apache 2.0. В 4-bit укладывается в < 8GB VRAM. |
| AWQ 4-bit квантизация | Сжатие с 14GB до ~5GB VRAM. Оптимизирован под inference, минимальные потери качества. |
| Transformers (HF) | Загрузка и inference модели. Нативная поддержка Qwen2-VL. |
| PyTorch + CUDA | GPU-inference. Поддержка FlashAttention, оптимизация памяти. |
| `llama.cpp` (CPU режим) | C++ engine для CPU через GGUF. Поддерживает multimodal. |

Альтернативные модели (если Qwen2.5-VL-7B не влезет):
- MiniCPM-V-2.6 — ~4GB, хороший OCR, Apache 2.0.
- Moondream 2 (0.5B) — ~1.8GB, ультракомпактная.

### Формат взаимодействия

| Параметр | Значение |
|---|---|
| Протокол | REST API (HTTP) |
| Вход | `multipart/form-data` (изображение) |
| Выход | `application/json` |
| Документация | Swagger UI автоматически на `/docs` |

### Инфраструктура

| Технология | Обоснование |
|---|---|
| Docker + docker-compose | Контейнеризация. Требование ТЗ. |
| NVIDIA Container Toolkit | GPU из Docker. CUDA-поддержка. |
| GPU: NVIDIA 8GB VRAM | Минимум по ТЗ. RTX 3060/4060. |
| CPU (резерв) | `llama.cpp` + GGUF. Бонус по ТЗ. |

### Дополнительно

| Технология | Обоснование |
|---|---|
| Gradio (UI) | Быстрый веб-интерфейс для демо. Загрузка изображений из коробки. |
| Mermaid (обратная задача) | Генерация диаграмм из текста. Опенсорс, MIT. |
| Pillow | Препроцессинг изображений. |
| Pydantic | Валидация данных + интеграция с FastAPI. |

### Лицензионная чистота

Все компоненты имеют открытые лицензии (Apache 2.0 / MIT / BSD) — требование ТЗ:

| Компонент | Лицензия |
|---|---|
| Qwen2.5-VL-7B | Apache 2.0 |
| FastAPI | MIT |
| PyTorch | BSD |
| Transformers | Apache 2.0 |
| Gradio | Apache 2.0 |
| `llama.cpp` | MIT |
| Mermaid | MIT |

## Раздел 3. План реализации (Roadmap)

| Этап | Срок | Задачи | Результат |
|---|---|---|---|
| 1. Анализ | 29 янв | Изучить ТЗ, примеры BPMN, определить вход/выход, выбрать модель | Понимание задачи, выбор модели |
| 2. Проверка модели | 30 янв | Запуск Qwen2.5-VL-7B (4-bit) на тестовых BPMN, подбор промптов | Модель распознаёт диаграммы |
| 3. Пайплайн | 31 янв | Препроцессинг + VLM + парсинг JSON | Вход → модель → выход работает |
| 4. REST API | 1 фев | FastAPI: POST /analyze, Swagger, обработка ошибок | API эндпоинт работает |
| 5. Docker | 2 фев | Dockerfile, docker-compose, GPU/CPU | Запуск одной командой |
| 6. UI + бонусы | 3–4 фев | Gradio UI, CPU-режим, обратная задача (Mermaid) | Полный сервис с UI |
| 7. Защита | 5–6 фев | Метрики, sizing, видео, GitHub, презентация | Финальная подача |

### Детализация

#### Этап 2: Проверка модели (критический)

Проверяем: способна ли Qwen2.5-VL-7B (4-bit) корректно распознавать BPMN и выдавать структурированный выход. Если нет — переход на MiniCPM-V.

- Тест: 5–10 BPMN-диаграмм разной сложности.
- Критерий: модель находит шаги, связи и роли.
- VRAM: подтверждаем < 8GB.

#### Этап 5: Docker

Примерно так будет выглядеть `docker-compose.yml` (черновик):

```yaml
services:
  app:
    # FastAPI + Uvicorn
    # VLM модель (загрузка при старте)
    # Gradio UI (опционально)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

#### Этап 6: Обратная задача (Text -> Diagram)

Используем ту же VLM в текстовом режиме: подаём описание алгоритма, просим сгенерировать Mermaid-код. Модель уже загружена.

### Sizing (оценка)

| Параметр | GPU (основной) | CPU (резерв) |
|---|---|---|
| VRAM / RAM | ~5–6 GB VRAM | ~8–10 GB RAM |
| Время на 1 изображение | 5–15 сек | 30–120 сек |
| Docker image | ~8–10 GB | ~6–8 GB |
| Модель на диске | ~4.5 GB (AWQ) | ~4.5 GB (GGUF Q4) |

Требование ТЗ: описание 1 картинки не более 20 сек — выполнимо на GPU.
